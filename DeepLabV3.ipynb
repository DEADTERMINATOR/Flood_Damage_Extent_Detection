{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1KMWS2Oyo4vVFS2GYmUhqId2DopiI21d6","authorship_tag":"ABX9TyNO6v/H6tc3abrfxRCEsT6Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"116airy7vw8bo75PG6P8_Fl8oNggQpfzh"},"id":"BDnqqojUpKLE","executionInfo":{"status":"ok","timestamp":1700442290003,"user_tz":480,"elapsed":2458886,"user":{"displayName":"DEADTERMINATOR","userId":"00537253248716777682"}},"outputId":"6090b0f9-8ac7-470d-9795-4c840cf0b953"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","import torchvision\n","from torchvision import models\n","import torchvision.transforms as transforms\n","from torchvision.transforms import Compose, Resize, v2\n","from torchvision.transforms.functional import to_tensor\n","\n","import os\n","import matplotlib.pyplot as plt\n","\n","from PIL import Image\n","\n","#import dataset\n","\n","\n","class HarveyData(Dataset):\n","    #dataset_dir: Provide a path to either \"./dataset/training\" or \"./dataset/testing\"\n","    #transforms: Any transformations that should be performed on the image when retrieved.\n","    def __init__(self, dataset_dir, transforms=None):\n","        super(HarveyData, self).__init__()\n","        self.dataset_dir = dataset_dir\n","        self.transforms = transforms\n","\n","        self.pre_image_paths = sorted(os.listdir(os.path.join(dataset_dir, 'pre_img')))\n","        self.post_image_paths = sorted(os.listdir(os.path.join(dataset_dir, 'post_img')))\n","        self.mask_paths = sorted(os.listdir(os.path.join(dataset_dir, 'post_msk')))\n","\n","        self.pre_images = []\n","        self.post_images = []\n","        self.masks = []\n","\n","        self.num_images = len(self.pre_image_paths)\n","\n","        for i in range(self.num_images):\n","            pre_image = Image.open(os.path.join(dataset_dir, 'pre_img', self.pre_image_paths[i]))\n","            post_image = Image.open(os.path.join(dataset_dir, 'post_img', self.post_image_paths[i]))\n","            mask = Image.open(os.path.join(dataset_dir, 'post_msk', self.mask_paths[i]))\n","\n","            self.pre_images.append(pre_image)\n","            self.post_images.append(post_image)\n","            self.masks.append(mask)\n","\n","    def __getitem__(self, idx):\n","        #Get pre and post image, and the mask, for the current index.\n","        pre_image = self.pre_images[idx]\n","        post_image = self.post_images[idx]\n","        mask = self.masks[idx]\n","\n","        #Convert image to normalized tensor.\n","        pre_image = to_tensor(pre_image)\n","        post_image = to_tensor(post_image)\n","        mask = to_tensor(mask)\n","\n","        if self.transforms is not None:\n","            pre_image = self.transforms(pre_image)\n","            post_image = self.transforms(post_image)\n","            mask = self.transforms(mask)\n","\n","        #Concatenate the pre and post disaster images together along the channel dimension.\n","        combined_image = torch.cat([pre_image, post_image], dim=0)\n","\n","        return combined_image, mask\n","\n","    def __len__(self):\n","        return self.num_images\n","\n","class DeepLabV3(nn.Module):\n","    def __init__(self, num_input_channels, num_classes):\n","        super(DeepLabV3, self).__init__()\n","        self.deeplabv3_weights = torchvision.models.segmentation.DeepLabV3_ResNet50_Weights.DEFAULT\n","        self.resnet50_weights = models.ResNet50_Weights.DEFAULT\n","        self.deeplabv3 = torchvision.models.segmentation.deeplabv3_resnet50(num_classes=num_classes, weights_backbone=self.resnet50_weights)\n","\n","        # Modify the first convolutional layer of the ResNet50 backbone to accept num_input_channels channels\n","        backbone_conv1 = nn.Conv2d(num_input_channels, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.modified_backbone = nn.Sequential(backbone_conv1,\n","                                              *list(self.deeplabv3.backbone.children())[1:])\n","        self.deeplabv3_head = nn.Sequential(*list(self.deeplabv3.children())[-1:])\n","        self.deeplabv3_combine = nn.Sequential(self.modified_backbone,\n","                                               self.deeplabv3_head)\n","\n","    def forward(self, x):\n","        #x = self.deeplabv3.forward(x)\n","        x = self.deeplabv3_combine.forward(x)\n","        return x\n","\n","batch_size = 16\n","num_input_channels = 6\n","num_classes = 4\n","lr = 1e-5\n","image_size = 224\n","\n","transforms = v2.Compose([\n","    v2.Resize((image_size, image_size), antialias=True),\n","    v2.RandomHorizontalFlip(p=0.5),\n","    v2.RandomVerticalFlip(p=0.5),\n","    v2.RandomRotation(degrees=(1, 359)),\n","    v2.RandomResizedCrop(size=image_size, antialias=True)\n","    ])\n","\n","cwd = os.getcwd()\n","\n","train_dataset = HarveyData(os.path.join(cwd, 'drive/MyDrive/dataset/training'), transforms=transforms)\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","test_dataset = HarveyData(os.path.join(cwd, 'drive/MyDrive/dataset/testing'), transforms=transforms)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = DeepLabV3(num_input_channels, num_classes).to(device)\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","num_epochs = 20\n","\n","predicted_images = []\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    epoch_loss = 0\n","    for i, data in enumerate(train_dataloader):\n","        image, mask = data\n","\n","        image = image.to(device)\n","        mask = mask.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(image)\n","\n","        mask_resize = Compose([v2.Resize((72, 72), antialias=True)])\n","        mask = mask_resize(mask)\n","\n","        loss = criterion(outputs, mask)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","        print('Batch %d --- Loss: %.4f' % (i, loss.item() / batch_size))\n","    print('Epoch %d / %d --- Average Loss: %.4f' % (epoch + 1, num_epochs, epoch_loss / train_dataset.__len__()))\n","\n","    model.eval()\n","    total_loss = 0.0\n","    correct_predictions = 0\n","    total_pixels = 0\n","    dice_score = 0.0\n","\n","    with torch.no_grad():\n","        for i, data in enumerate(test_dataloader):\n","            image, mask = data\n","\n","            image = image.to(device)\n","            mask = mask.to(device)\n","\n","            outputs = model(image)\n","\n","            mask_resize = Compose([v2.Resize((72, 72), antialias=True)])\n","            mask = mask_resize(mask)\n","\n","            loss = criterion(outputs, mask)\n","            total_loss += loss.item()\n","\n","            softmax = nn.Softmax(dim=1)\n","            predicted = torch.argmax(softmax(model(image)), axis=1, keepdim=True)\n","            predicted_images.append(predicted.cpu().numpy())\n","\n","            correct_predictions += (predicted == mask).sum()\n","            total_pixels += torch.numel(predicted)\n","            dice_score += (2 * (predicted * mask).sum()) / ((predicted + mask).sum() + 1e-8)\n","\n","    accuracy = correct_predictions / total_pixels * 100\n","    average_loss = total_loss / len(test_dataloader)\n","    dice_score = dice_score / len(test_dataset)\n","\n","    print('Accuracy: %.4f ---- Loss: %.4f ---- Dice: %.4f' % (accuracy, total_loss / test_dataset.__len__(), dice_score))\n","\n","fig, axs = plt.subplots(8, 3, figsize=(32, 32))\n","\n","for i in range(8):\n","    # Plot the input image\n","    image, mask = test_dataset.__getitem__(i)\n","    axs[i, 0].imshow(image.numpy()[3:6, :, :].T, aspect='equal')\n","    axs[i, 0].set_title(\"Input Image\")\n","    axs[i, 0].axis('off')\n","\n","    # Plot the predicted image\n","    predicted_images_flat = [item for sublist in predicted_images for item in sublist]\n","    axs[i, 1].imshow(predicted_images_flat[i].T, cmap=\"viridis\", aspect='equal')  # Adjust the colormap as needed\n","    axs[i, 1].set_title(\"Predicted Image\")\n","    axs[i, 1].axis('off')\n","\n","    # Plot the ground truth mask\n","    axs[i, 2].imshow(mask.numpy()[0].T, cmap=\"viridis\", aspect='equal')  # Assuming the mask is a single-channel image\n","    axs[i, 2].set_title(\"Ground Truth Mask\")\n","    axs[i, 2].axis('off')\n","\n","plt.show()"]}]}